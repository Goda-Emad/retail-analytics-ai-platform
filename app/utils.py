import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error
import time

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ø­Ù…Ø§ÙŠØ© (Guardrail) Ø§Ù„Ù…Ø¨ØªÙƒØ±Ø© Ø¨ÙˆØ§Ø³Ø·Ø© ENG.GODA EMAD ---
def apply_forecast_guardrail(forecast_values, historical_series):
    """
    ØªØ·Ø¨ÙŠÙ‚ Ù‚ÙŠÙˆØ¯ Ø°ÙƒÙŠØ© Ù„Ù…Ù†Ø¹ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ø§Ù†ÙØ¬Ø§Ø±ÙŠ (Explosive Growth) 
    ÙˆØªÙ†Ø¹ÙŠÙ… Ø§Ù„Ù…Ù†Ø­Ù†Ù‰ Ù„Ø¶Ù…Ø§Ù† Ù…Ù†Ø·Ù‚ÙŠØ© Ø§Ù„Ù†ØªØ§Ø¦Ø¬.
    """
    forecast = pd.Series(forecast_values).copy()

    # 1. Ø§Ù„Ø³Ù‚Ù Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ (Historical Ceiling)
    hist_max = historical_series.max()
    ceiling = hist_max * 1.25  # Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø²ÙŠØ§Ø¯Ø© 25% ÙÙ‚Ø· Ø¹Ù† Ø£Ø¹Ù„Ù‰ Ù‚Ù…Ø© ØªØ§Ø±ÙŠØ®ÙŠØ©

    # 2. ÙƒØ§Ø¨Ø­ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„ÙŠÙˆÙ…ÙŠ (Growth Cap)
    max_daily_growth = 1.15  # Ù…Ù†Ø¹ Ø§Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ø¹Ù† 15%
    for i in range(1, len(forecast)):
        allowed = forecast[i-1] * max_daily_growth
        forecast[i] = min(forecast[i], allowed)

    # 3. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø³Ù‚Ù ÙˆØªÙ†Ø¹ÙŠÙ… Ø§Ù„Ù…Ù†Ø­Ù†Ù‰ (Smoothing)
    forecast = np.minimum(forecast, ceiling)
    # ØªÙ†Ø¹ÙŠÙ… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ù„Ø«Ù„Ø§Ø«Ø© Ø£ÙŠØ§Ù…
    forecast = forecast.rolling(window=3, min_periods=1).mean()

    return forecast.values

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ù€ Backtesting Ø§Ù„Ù…Ø­Ø¯Ø«Ø© ---
def run_backtesting(_df, feature_names, _scaler, _model):
    start_time = time.time()
    
    # ØªÙ†Ø¸ÙŠÙ Ø£ÙˆÙ„ÙŠ Ù„Ù„Ø¯Ø§ØªØ§
    _df = _df.copy().replace([np.inf, -np.inf], np.nan).dropna(subset=['sales'])
    
    n_splits = 3
    if len(_df) < (n_splits + 1) * 7:
        n_splits = 2
        
    tscv = TimeSeriesSplit(n_splits=n_splits)
    results = []
    all_residuals = []
    
    num_cols = ['lag_1', 'lag_7', 'rolling_mean_7', 'rolling_mean_14']
    
    for train_index, test_index in tscv.split(_df):
        train_df = _df.iloc[train_index]
        test_df = _df.iloc[test_index].copy()
        X_test = test_df[feature_names].copy()
        
        # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Scaling)
        X_test = X_test.ffill().bfill().fillna(0)
        try:
            X_test[num_cols] = _scaler.transform(X_test[num_cols])
        except:
            X_test_scaled = _scaler.transform(X_test)
            X_test = pd.DataFrame(X_test_scaled, columns=feature_names, index=X_test.index)
        
        # Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù„ÙˆØºØ§Ø±ÙŠØªÙ…ÙŠ
        preds_log = _model.predict(X_test)
        # Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
        raw_preds = np.expm1(preds_log)
        
        # ğŸ”¥ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù€ Guardrail Ø¯Ø§Ø®Ù„ Ø§Ù„Ù€ Backtesting Ù„Ø¶Ù…Ø§Ù† Ø¯Ù‚Ø© Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        preds = apply_forecast_guardrail(raw_preds, train_df['sales'])
        
        actuals = test_df['sales'].values
        preds = np.nan_to_num(preds, nan=0.0, posinf=actuals.max()*2, neginf=0.0)
        preds = np.maximum(preds, 0)
        
        residuals = actuals - preds
        all_residuals.extend(residuals)
        
        try:
            results.append({
                'mape': mean_absolute_percentage_error(actuals, preds),
                'rmse': np.sqrt(mean_squared_error(actuals, preds)),
                'r2': r2_score(np.log1p(actuals), np.log1p(preds))
            })
        except:
            continue
    
    if not results:
        return {'mape': 0.1, 'rmse': 0, 'r2': 0, 'residuals_std': 1.0, 
                'execution_time': 0, 'data_points': len(_df), 'features_count': len(feature_names)}

    metrics_avg = pd.DataFrame(results).mean().to_dict()
    metrics_avg['residuals_std'] = np.std(all_residuals) if all_residuals else 1.0
    metrics_avg['execution_time'] = time.time() - start_time
    metrics_avg['data_points'] = len(_df)
    metrics_avg['features_count'] = len(feature_names)
    
    return metrics_avg
