import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error
import time

# =========================================================
# ğŸ”’ Forecast Guardrail
# =========================================================
def apply_forecast_guardrail(forecast_values, historical_series):
    forecast = pd.Series(forecast_values).copy()
    hist_max = historical_series.max()
    ceiling = hist_max * 1.25
    max_daily_growth = 1.15

    for i in range(1, len(forecast)):
        allowed = forecast[i-1] * max_daily_growth
        forecast[i] = min(forecast[i], allowed)

    forecast = np.minimum(forecast, ceiling)
    forecast = forecast.rolling(window=3, min_periods=1).mean()
    return forecast.values

# =========================================================
# ğŸš€ Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª (Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙŠ Ø³Ø¨Ø¨Øª Ø§Ù„Ø®Ø·Ø£)
# =========================================================
def generate_forecast(df, horizon, multiplier, residuals_std, use_guardrail=True):
    """
    Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù‡ÙŠ Ø§Ù„ØªÙŠ ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø³Ø§Ø¯Ø³ Ù…Ù† Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯.
    ØªÙ… Ø¥Ø¶Ø§ÙØ© use_guardrail=True Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù€ TypeError.
    """
    # Ù…Ù„Ø§Ø­Ø¸Ø©: ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø³ÙƒÙŠÙ„Ø± Ù…Ø¹Ø±ÙÙŠÙ† Ø¹Ø§Ù„Ù…ÙŠØ§Ù‹ Ø£Ùˆ ÙŠØªÙ… ØªÙ…Ø±ÙŠØ±Ù‡Ù…
    # Ù‡Ù†Ø§ Ø³Ù†ÙØªØ±Ø¶ ÙˆØ¬ÙˆØ¯Ù‡Ù… Ø£Ùˆ Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡Ù… Ù…Ù† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
    
    # Ù…Ù†Ø·Ù‚ Ù…Ø¨Ø³Ø· Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª (Recursive Loop)
    historical_max = df['sales'].max()
    prev_value = df['sales'].iloc[-1]
    predictions = []
    
    # --- Ù…Ø­Ø§ÙƒØ© Ø§Ù„Ù„ÙˆØ¨ (ÙŠØ¬Ø¨ Ø¯Ù…Ø¬ Ù…Ù†Ø·Ù‚ Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù‡Ù†Ø§) ---
    # Ù‡Ø°Ø§ Ù…Ø¬Ø±Ø¯ Ù‡ÙŠÙƒÙ„ Ù„Ø¶Ù…Ø§Ù† Ø¹Ù…Ù„ Ø§Ù„ÙƒÙˆØ¯ Ø¯ÙˆÙ† Ø£Ø®Ø·Ø§Ø¡
    for step in range(horizon):
        # Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ (Ø§Ø³ØªØ¨Ø¯Ù„Ù‡ Ø¨Ù€ model.predict Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ)
        raw_pred = prev_value * 1.05 * multiplier 
        
        if use_guardrail:
            allowed_growth = prev_value * 1.15
            ceiling = historical_max * 1.25
            safe_pred = min(raw_pred, allowed_growth, ceiling)
        else:
            safe_pred = raw_pred
            
        predictions.append(safe_pred)
        prev_value = safe_pred

    final_p = pd.Series(predictions).rolling(3, min_periods=1).mean().values
    
    # Ø¥Ø±Ø¬Ø§Ø¹ 4 Ù‚ÙŠÙ… Ù„ÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ p, _, _, _ ÙÙŠ Ø§Ù„Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
    return final_p, None, None, None

# =========================================================
# ğŸ“Š Backtesting (Ù†ÙØ³ ÙƒÙˆØ¯Ùƒ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
# =========================================================
def run_backtesting(_df, feature_names, _scaler, _model):
    start_time = time.time()
    _df = _df.copy().replace([np.inf, -np.inf], np.nan).dropna(subset=['sales'])

    n_splits = 3
    if len(_df) < (n_splits + 1) * 7:
        n_splits = 2

    tscv = TimeSeriesSplit(n_splits=n_splits)
    results = []
    all_residuals = []
    num_cols = ['lag_1', 'lag_7', 'rolling_mean_7', 'rolling_mean_14']

    for train_index, test_index in tscv.split(_df):
        test_df = _df.iloc[test_index].copy()
        X_test = test_df[feature_names].copy()
        X_test = X_test.ffill().bfill().fillna(0)

        try:
            X_test[num_cols] = _scaler.transform(X_test[num_cols])
        except:
            X_test_scaled = _scaler.transform(X_test)
            X_test = pd.DataFrame(X_test_scaled, columns=feature_names, index=X_test.index)

        preds_log = _model.predict(X_test)
        preds = np.expm1(preds_log)
        actuals = test_df['sales'].values
        preds = np.nan_to_num(preds, nan=0.0, posinf=actuals.max()*2, neginf=0.0)
        preds = np.maximum(preds, 0)

        residuals = actuals - preds
        all_residuals.extend(residuals)

        try:
            results.append({
                'mape': mean_absolute_percentage_error(actuals, preds),
                'rmse': np.sqrt(mean_squared_error(actuals, preds)),
                'r2': r2_score(np.log1p(actuals), preds_log)
            })
        except:
            continue

    if not results:
        return {'mape': 0.1, 'rmse': 0, 'r2': 0, 'residuals_std': 1.0, 
                'execution_time': 0, 'data_points': len(_df), 'features_count': len(feature_names)}

    metrics_avg = pd.DataFrame(results).mean().to_dict()
    metrics_avg['residuals_std'] = np.std(all_residuals) if all_residuals else 1.0
    metrics_avg['execution_time'] = time.time() - start_time
    metrics_avg['data_points'] = len(_df)
    metrics_avg['features_count'] = len(feature_names)

    return metrics_avg
