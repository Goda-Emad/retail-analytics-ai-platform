import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import timedelta
import joblib
import time
import os
from utils import run_backtesting 

# ================== 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ÙŠØ§Øª ==================
st.set_page_config(page_title="Retail AI Pro Max", layout="wide", page_icon="ğŸ“ˆ")

# CSS Ù„Ø¥Ø¶Ø§ÙØ© Ù„Ù…Ø³Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©
st.markdown("""
    <style>
    .main { background-color: #0e1117; }
    .stMetric { background-color: #1e293b; padding: 15px; border-radius: 10px; border: 1px solid #334155; }
    </style>
    """, unsafe_allow_html=True)

# ================== 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ØµÙˆÙ„ (Ù…Ø¹ Cache) ==================
@st.cache_resource
def load_assets():
    try:
        model = joblib.load("catboost_sales_model_10features.pkl")
        scaler = joblib.load("scaler_10features.pkl")
        features = joblib.load("feature_names_10features.pkl")
        df = pd.read_parquet("daily_sales_ready_10features.parquet")
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df.columns = [str(c).lower().strip() for c in df.columns]
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
            df = df.sort_values('date').set_index('date')
        return model, scaler, features, df
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
        return None, None, None, None

model, scaler, feature_names, df_init = load_assets()

# ================== 3. ÙˆØ¸ÙŠÙØ© Ø§Ù„ØªÙˆÙ‚Ø¹ (Ø§Ù„Ù…Ø­Ø±Ùƒ) ==================
def generate_forecast(history_df, horizon, scenario_factor, noise_val, residuals_std):
    start_time = time.time()
    preds, lowers, uppers = [], [], []
    current_df = history_df[['sales']].copy()
    num_cols = ['lag_1', 'lag_7', 'rolling_mean_7', 'rolling_mean_14']
    
    for i in range(horizon):
        next_date = current_df.index[-1] + timedelta(days=1)
        feat_dict = {
            'dayofweek_sin': np.sin(2 * np.pi * next_date.dayofweek / 7),
            'dayofweek_cos': np.cos(2 * np.pi * next_date.dayofweek / 7),
            'month_sin': np.sin(2 * np.pi * (next_date.month - 1) / 12),
            'month_cos': np.cos(2 * np.pi * (next_date.month - 1) / 12),
            'lag_1': float(current_df['sales'].iloc[-1]),
            'lag_7': float(current_df['sales'].iloc[-7] if len(current_df)>=7 else current_df['sales'].mean()),
            'rolling_mean_7': float(current_df['sales'].tail(7).mean()),
            'rolling_mean_14': float(current_df['sales'].tail(14).mean()),
            'is_weekend': 1 if next_date.dayofweek >= 5 else 0,
            'was_closed_yesterday': 1 if current_df['sales'].iloc[-1] == 0 else 0
        }
        
        X_df = pd.DataFrame([feat_dict])[feature_names] # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        X_df[num_cols] = scaler.transform(X_df[num_cols]) # Ø§Ù„Ù€ Scaling
        
        pred = np.expm1(model.predict(X_df)[0]) * scenario_factor
        pred_final = max(0, pred * (1 + np.random.normal(0, noise_val)))
        
        # Confidence Interval Ø­Ù‚ÙŠÙ‚ÙŠ
        bound = (i + 1)**0.5 * residuals_std 
        
        preds.append(pred_final)
        lowers.append(max(0, pred_final - bound))
        uppers.append(pred_final + bound)
        current_df = pd.concat([current_df, pd.Series([pred_final], index=[next_date], name='sales').to_frame()])
    
    return preds, lowers, uppers, current_df.index[-horizon:], time.time() - start_time

# ================== 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Sidebar) ==================
if model is not None:
    st.sidebar.title("ğŸ® Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    
    # Ù…ÙŠØ²Ø© 7: Ø±ÙØ¹ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯
    uploaded_file = st.sidebar.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© (CSV)", type="csv")
    if uploaded_file:
        df_init = pd.read_csv(uploaded_file, index_col='date', parse_dates=True)
        st.sidebar.success("ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©!")

    # Ù…ÙŠØ²Ø© 8: Ø¯Ø¹Ù… ÙØ±ÙˆØ¹ Ù…ØªØ¹Ø¯Ø¯Ø© (Multi-Store)
    stores = df_init['store_id'].unique() if 'store_id' in df_init.columns else ["Ø§Ù„ÙØ±Ø¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"]
    selected_store = st.sidebar.selectbox("ğŸª Ø§Ø®ØªØ± Ø§Ù„ÙØ±Ø¹", stores)
    
    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙØ±Ø¹
    if 'store_id' in df_init.columns:
        df_final = df_init[df_init['store_id'] == selected_store]
    else:
        df_final = df_init

    st.sidebar.divider()
    horizon = st.sidebar.slider("Ù…Ø¯Ø© Ø§Ù„ØªÙˆÙ‚Ø¹ (Ø£ÙŠØ§Ù…)", 7, 60, 14)
    scenario = st.sidebar.select_slider("Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø³ÙˆÙ‚", options=["Ù…ØªØ´Ø§Ø¦Ù…", "ÙˆØ§Ù‚Ø¹ÙŠ", "Ù…ØªÙØ§Ø¦Ù„"], value="ÙˆØ§Ù‚Ø¹ÙŠ")
    sc_map = {"Ù…ØªØ´Ø§Ø¦Ù…": 0.85, "ÙˆØ§Ù‚Ø¹ÙŠ": 1.0, "Ù…ØªÙØ§Ø¦Ù„": 1.15}
    noise = st.sidebar.slider("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ‚Ù„Ø¨", 0.0, 0.2, 0.05)

    # ================== 5. Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ù„Ù€ Metrics ==================
    st.title("ğŸš€ Retail AI Forecast Engine")
    st.markdown(f"Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€: **{selected_store}**")

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ Backtesting (Cached)
    with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø¯Ù‚Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„..."):
        metrics = run_backtesting(df_final, feature_names, scaler, model)

    # ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙˆÙ‚Ø¹
    preds, lowers, uppers, dates, inf_time = generate_forecast(
        df_final, horizon, sc_map[scenario], noise, metrics['residuals_std']
    )

    # Ù…ÙŠØ²Ø© 1 & 5: Ø¹Ø±Ø¶ KPIs Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙˆØ²Ù…Ù† Ø§Ù„ØªÙ†ÙÙŠØ°
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„ÙƒÙ„ÙŠ", f"${np.sum(preds):,.0f}")
    c2.metric("Ø¯Ù‚Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (RÂ²)", f"{metrics['r2']*100:.1f}%")
    c3.metric("Ù†Ø³Ø¨Ø© Ø§Ù„Ø®Ø·Ø£ (MAPE)", f"{metrics['mape']*100:.2f}%")
    c4.metric("Ø²Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", f"{inf_time*1000:.1f} ms")

    # ================== 6. Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… ==================
    fig = go.Figure()
    # Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ©
    fig.add_trace(go.Scatter(x=df_final.index[-45:], y=df_final['sales'].tail(45), name="Ù…Ø¨ÙŠØ¹Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©", line=dict(color="#94a3b8")))
    # Ù†Ø·Ø§Ù‚ Ø§Ù„Ø«Ù‚Ø© (Confidence Interval)
    fig.add_trace(go.Scatter(x=np.concatenate([dates, dates[::-1]]), y=np.concatenate([uppers, lowers[::-1]]),
                             fill='toself', fillcolor='rgba(59, 130, 246, 0.2)', line=dict(color='rgba(255,255,255,0)'), name="Ù†Ø·Ø§Ù‚ Ø§Ù„Ø´Ùƒ"))
    # Ø§Ù„ØªÙˆÙ‚Ø¹
    fig.add_trace(go.Scatter(x=dates, y=preds, name="ØªÙˆÙ‚Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", line=dict(color="#3b82f6", width=4)))

    fig.update_layout(template="plotly_dark", height=500, margin=dict(l=20, r=20, t=20, b=20))
    st.plotly_chart(fig, use_container_width=True)

    # Ù…ÙŠØ²Ø© 6: ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
    st.divider()
    res_df = pd.DataFrame({"Date": dates, "Forecast": preds, "Upper": uppers, "Lower": lowers})
    st.download_button(label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª (CSV)", data=res_df.to_csv().encode('utf-8'),
                       file_name=f'forecast_{selected_store}.csv', mime='text/csv')

    # Ù…ÙŠØ²Ø© 9: Logging Ø¨Ø³ÙŠØ· ÙÙŠ Ø§Ù„ØµÙØ­Ø©
    with st.expander("ğŸ› ï¸ ØªÙØ§ØµÙŠÙ„ ÙÙ†ÙŠØ© (System Logs)"):
        st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {len(df_final)}")
        st.write(f"Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: {', '.join(feature_names)}")
        st.write(f"Ø­Ø§Ù„Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„: Stable")
